name: Consulta y PDF de Wikipedia

on:
  workflow_dispatch:
    inputs:
      MM:
        description: 'Mes (MM)'
        required: true
        default: '01'
      DD:
        description: 'Día (DD)'
        required: true
        default: '01'

jobs:
  fetch-and-prepare:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    env:
      LANG: ${{ vars.LANG }}

    steps:
      - name: Obtener eventos y construir matriz
        id: set-matrix
        run: |
          LANGUAGE=$LANG
          MONTH=${{ github.event.inputs.MM }}
          DAY=${{ github.event.inputs.DD }}
          FILENAME=wikimedia_${LANGUAGE}_${MONTH}-${DAY}.json

          URL="https://api.wikimedia.org/feed/v1/wikipedia/${LANGUAGE}/onthisday/selected/${MONTH}/${DAY}"
          RESPONSE=$(curl -s "$URL")
          echo "$RESPONSE" > $FILENAME

          mkdir -p shared
          cp $FILENAME shared/

          MATRIX=$(jq -c '[.selected | to_entries | .[].key | tostring]' <<< "$RESPONSE")
          echo "matrix=$MATRIX" >> "$GITHUB_OUTPUT"

      - name: Guardar JSON como artefacto temporal
        uses: actions/upload-artifact@v4
        with:
          name: wikimedia-json
          path: shared/
          retention-days: 1

  procesar-eventos:
    needs: fetch-and-prepare
    runs-on: ubuntu-latest
    strategy:
      matrix:
        index: ${{ fromJson(needs.fetch-and-prepare.outputs.matrix) }}
    env:
      LANG: ${{ vars.LANG }}
      MM: ${{ github.event.inputs.MM }}
      DD: ${{ github.event.inputs.DD }}

    steps:
      - name: Instalar wkhtmltopdf
        run: |
          sudo apt-get update
          sudo apt-get install -y wkhtmltopdf

      - name: Descargar JSON desde artefacto
        uses: actions/download-artifact@v4
        with:
          name: wikimedia-json
          path: shared/

      - name: Extraer datos del evento
        id: evento
        run: |
          LANGUAGE=$LANG
          INDEX=${{ matrix.index }}
          FILENAME=wikimedia_${LANGUAGE}_${MM}-${DD}.json

          EVENT=$(jq ".selected[$INDEX]" shared/$FILENAME)
          TITLE=$(echo "$EVENT" | jq -r '.pages[0].title // "Sin_título"')
          URL=$(echo "$EVENT" | jq -r '.pages[0].content_urls.desktop.page // empty')

          if [ -z "$URL" ]; then
            echo "No URL para evento #$INDEX, se omite."
            echo "skip=true" >> "$GITHUB_OUTPUT"
          else
            SAFE_TITLE=$(echo "$TITLE" | tr ' /' '__')
            FILENAME_PDF="${MM}-${DD}-${SAFE_TITLE}.pdf"

            echo "title=$SAFE_TITLE" >> "$GITHUB_OUTPUT"
            echo "url=$URL" >> "$GITHUB_OUTPUT"
            echo "filename=$FILENAME_PDF" >> "$GITHUB_OUTPUT"
            echo "skip=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Generar PDF desde URL con wkhtmltopdf
        if: steps.evento.outputs.skip != 'true'
        run: |
          mkdir -p pdfs
          wkhtmltopdf "${{ steps.evento.outputs.url }}" "pdfs/${{ steps.evento.outputs.filename }}"

      - name: Subir PDF individual
        if: steps.evento.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: pdf-${{ matrix.index }}
          path: pdfs/
          retention-days: 1

  empaquetar-todos-los-pdfs:
    needs: procesar-eventos
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Descargar todos los PDFs
        uses: actions/download-artifact@v4
        with:
          path: all_pdfs/

      - name: Crear ZIP con todos los PDFs
        run: |
          mkdir -p output
          zip -r output/eventos_wikipedia_${{ github.event.inputs.MM }}-${{ github.event.inputs.DD }}.zip all_pdfs/

      - name: Subir archivo ZIP como artefacto final
        uses: actions/upload-artifact@v4
        with:
          name: Eventos-Wikipedia-PDFs
          path: output/

